{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LSTM CODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import yfinance as yf\n",
    "import os\n",
    "from tabulate import tabulate\n",
    "from sklearn.metrics import r2_score \n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import LSTM\n",
    "# from itertools import cycle\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create dataset for time-series prediction\n",
    "def create_dataset(dataset, time_step=1):\n",
    "    dataX, dataY = [], []\n",
    "    for i in range(len(dataset) - time_step - 1):\n",
    "        a = dataset[i:(i + time_step), 0]\n",
    "        dataX.append(a)\n",
    "        dataY.append(dataset[i + time_step, 0])\n",
    "    return np.array(dataX), np.array(dataY)\n",
    "\n",
    "# Main function to get predicted values\n",
    "def getpredictedvalues(selectedscript_1, start_date='2021-01-01', end_date='2025-01-01'):\n",
    "    selectedscript_2 = selectedscript_1.dropna().reset_index(drop=True)\n",
    "    selectedscript = selectedscript_2.copy()\n",
    "    selectedscript['Date'] = pd.to_datetime(selectedscript['Date'], format='%Y-%m-%d')\n",
    "    if start_date and end_date:\n",
    "        selectedscript = selectedscript[(selectedscript['Date'] >= start_date) & (selectedscript['Date'] <= end_date)]\n",
    "    selectedscript = selectedscript.set_index('Date')\n",
    "    close_df = selectedscript[['Close']].reset_index()\n",
    "    close_stock = close_df.copy()\n",
    "    del close_df['Date']\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    closedf = scaler.fit_transform(np.array(close_df).reshape(-1, 1))\n",
    "    training_size = int(len(closedf) * 0.80)\n",
    "    test_size = len(closedf) - training_size\n",
    "    train_data, test_data = closedf[0:training_size, :], closedf[training_size:len(closedf), :1]\n",
    "    time_step = 13\n",
    "    X_train, y_train = create_dataset(train_data, time_step)\n",
    "    X_test, y_test = create_dataset(test_data, time_step)\n",
    "    X_train = X_train.reshape(X_train.shape[0], X_train.shape[1], 1)\n",
    "    X_test = X_test.reshape(X_test.shape[0], X_test.shape[1], 1)\n",
    "    model = Sequential([\n",
    "        LSTM(32, return_sequences=True, input_shape=(time_step, 1)),\n",
    "        LSTM(32, return_sequences=True),\n",
    "        LSTM(32),\n",
    "        Dense(1)\n",
    "    ])\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=100, batch_size=32, verbose=1)\n",
    "    train_predict = model.predict(X_train)\n",
    "    test_predict = model.predict(X_test)\n",
    "    train_predict = scaler.inverse_transform(train_predict)\n",
    "    test_predict = scaler.inverse_transform(test_predict)\n",
    "    original_ytrain = scaler.inverse_transform(y_train.reshape(-1, 1))\n",
    "    original_ytest = scaler.inverse_transform(y_test.reshape(-1, 1))\n",
    "    train_r2_lstm = r2_score(original_ytrain, train_predict)\n",
    "    test_r2_lstm = r2_score(original_ytest, test_predict)\n",
    "    look_back = time_step\n",
    "    x_input = test_data[len(test_data) - time_step:].reshape(1, -1)\n",
    "    temp_input = list(x_input)[0].tolist()\n",
    "    lst_output = []\n",
    "    n_steps = time_step\n",
    "    pred_days = 5\n",
    "    i = 0\n",
    "    while i < pred_days:\n",
    "        if len(temp_input) > time_step:\n",
    "            x_input = np.array(temp_input[1:]).reshape(1, -1)\n",
    "            x_input = x_input.reshape((1, n_steps, 1))\n",
    "            yhat = model.predict(x_input, verbose=0)\n",
    "            temp_input.extend(yhat[0].tolist())\n",
    "            temp_input = temp_input[1:]\n",
    "            lst_output.extend(yhat.tolist())\n",
    "            i += 1\n",
    "        else:\n",
    "            x_input = x_input.reshape((1, n_steps, 1))\n",
    "            yhat = model.predict(x_input, verbose=0)\n",
    "            temp_input.extend(yhat[0].tolist())\n",
    "            lst_output.extend(yhat.tolist())\n",
    "            i += 1\n",
    "    lstmdf = scaler.inverse_transform(np.array(closedf.tolist() + lst_output).reshape(-1, 1)).flatten().tolist()\n",
    "    finaldf = pd.DataFrame({'Close': lstmdf})\n",
    "    data = {\"Model\": [\"LSTM\"], \"Train R2 Score\": [train_r2_lstm], \"Test R2 Score\": [test_r2_lstm]}\n",
    "    df = pd.DataFrame(data)\n",
    "    return df, finaldf, selectedscript"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File found: C://Users//manoj//Downloads//Major project data//Major pro source codes//DATASETS//filtered_indices_output.csv\n",
      "Epoch 1/10\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 43ms/step - loss: 0.1284 - val_loss: 0.0592\n",
      "Epoch 2/10\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0083 - val_loss: 0.0256\n",
      "Epoch 3/10\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.0041 - val_loss: 0.0148\n",
      "Epoch 4/10\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0030 - val_loss: 0.0030\n",
      "Epoch 5/10\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0022 - val_loss: 0.0061\n",
      "Epoch 6/10\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0027 - val_loss: 0.0027\n",
      "Epoch 7/10\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0022 - val_loss: 0.0027\n",
      "Epoch 8/10\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0021 - val_loss: 0.0021\n",
      "Epoch 9/10\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0022 - val_loss: 0.0048\n",
      "Epoch 10/10\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0022 - val_loss: 0.0026\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "Epoch 1/10\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 44ms/step - loss: 0.0894 - val_loss: 0.0905\n",
      "Epoch 2/10\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0075 - val_loss: 0.0377\n",
      "Epoch 3/10\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.0034 - val_loss: 0.0149\n",
      "Epoch 4/10\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0025 - val_loss: 0.0066\n",
      "Epoch 5/10\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0022 - val_loss: 0.0036\n",
      "Epoch 6/10\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0021 - val_loss: 0.0046\n",
      "Epoch 7/10\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0020 - val_loss: 0.0032\n",
      "Epoch 8/10\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0021 - val_loss: 0.0032\n",
      "Epoch 9/10\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0021 - val_loss: 0.0030\n",
      "Epoch 10/10\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0019 - val_loss: 0.0044\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "Epoch 1/10\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 40ms/step - loss: 0.0460 - val_loss: 0.0419\n",
      "Epoch 2/10\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0034 - val_loss: 0.0124\n",
      "Epoch 3/10\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0015 - val_loss: 0.0042\n",
      "Epoch 4/10\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0014 - val_loss: 0.0051\n",
      "Epoch 5/10\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.0012 - val_loss: 0.0119\n",
      "Epoch 6/10\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0013 - val_loss: 0.0041\n",
      "Epoch 7/10\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.0012 - val_loss: 0.0043\n",
      "Epoch 8/10\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0012 - val_loss: 0.0044\n",
      "Epoch 9/10\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0013 - val_loss: 0.0036\n",
      "Epoch 10/10\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0010 - val_loss: 0.0036\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "Epoch 1/10\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 38ms/step - loss: 0.0086 - val_loss: 0.1561\n",
      "Epoch 2/10\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0011 - val_loss: 0.1125\n",
      "Epoch 3/10\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 8.3582e-04 - val_loss: 0.0710\n",
      "Epoch 4/10\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 6.4672e-04 - val_loss: 0.0330\n",
      "Epoch 5/10\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 7.3669e-04 - val_loss: 0.0148\n",
      "Epoch 6/10\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 7.3853e-04 - val_loss: 0.0203\n",
      "Epoch 7/10\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 6.3259e-04 - val_loss: 0.0207\n",
      "Epoch 8/10\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 6.2813e-04 - val_loss: 0.0251\n",
      "Epoch 9/10\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 6.3806e-04 - val_loss: 0.0211\n",
      "Epoch 10/10\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 6.0315e-04 - val_loss: 0.0172\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\n",
      "Predictions saved to C://Users//manoj//Downloads//Major project data//Major pro source codes//DATASETS//lstm_prediction_output.csv\n",
      "\n",
      "Final Output:\n",
      "╒════════════╤══════════════╤═════════╤══════════════════╤═════════════════╤══════════╤══════════╤══════════╤═════════╤══════════╕\n",
      "│ Run Date   │ Index Name   │ Model   │   Train R2 Score │   Test R2 Score │    Day 1 │    Day 2 │    Day 3 │   Day 4 │    Day 5 │\n",
      "╞════════════╪══════════════╪═════════╪══════════════════╪═════════════════╪══════════╪══════════╪══════════╪═════════╪══════════╡\n",
      "│ 2025-02-02 │ JSWSTEEL.NS  │ LSTM    │         0.906404 │        0.433492 │ 923.571  │ 916.347  │ 910.21   │ 905.972 │ 903.234  │\n",
      "├────────────┼──────────────┼─────────┼──────────────────┼─────────────────┼──────────┼──────────┼──────────┼─────────┼──────────┤\n",
      "│ 2025-02-02 │ HINDALCO.NS  │ LSTM    │         0.878491 │        0.134763 │ 617.109  │ 612.625  │ 608.816  │ 606.044 │ 603.732  │\n",
      "├────────────┼──────────────┼─────────┼──────────────────┼─────────────────┼──────────┼──────────┼──────────┼─────────┼──────────┤\n",
      "│ 2025-02-02 │ NMDC.NS      │ LSTM    │         0.955762 │        0.521927 │  72.0183 │  71.1986 │  70.5061 │  70.02  │  69.8691 │\n",
      "├────────────┼──────────────┼─────────┼──────────────────┼─────────────────┼──────────┼──────────┼──────────┼─────────┼──────────┤\n",
      "│ 2025-02-02 │ HINDZINC.NS  │ LSTM    │         0.593439 │        0.428804 │ 443.769  │ 439.688  │ 435.815  │ 432.368 │ 429.213  │\n",
      "╘════════════╧══════════════╧═════════╧══════════════════╧═════════════════╧══════════╧══════════╧══════════╧═════════╧══════════╛\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import datetime as dt  # Import the datetime module\n",
    "from tabulate import tabulate  # Import tabulate for better table formatting\n",
    "\n",
    "# Paths and configurations\n",
    "file_path = 'C://Users//manoj//Downloads//Major project data//Major pro source codes//DATASETS//filtered_indices_output.csv'\n",
    "daily_data_path = 'C://Users//manoj//Downloads//Major project data//Major pro source codes//DATASETS//Daily_data'\n",
    "output_csv_file = 'C://Users//manoj//Downloads//Major project data//Major pro source codes//DATASETS//lstm_prediction_output.csv'\n",
    "\n",
    "try:\n",
    "    # Check if the file exists\n",
    "    if os.path.exists(file_path):\n",
    "        print(f\"File found: {file_path}\")\n",
    "        selected_indices = pd.read_csv(file_path, on_bad_lines='skip')  # Updated line\n",
    "    else:\n",
    "        print(f\"File not found: {file_path}\")\n",
    "        raise FileNotFoundError(f\"The specified file does not exist: {file_path}\")\n",
    "\n",
    "    all_output_data = []\n",
    "    unique_index_codes = selected_indices['indexcode'].unique()\n",
    "    current_date = dt.datetime.now().strftime(\"%Y-%m-%d\")\n",
    "\n",
    "    for index_code in unique_index_codes:\n",
    "        filtered_indices = selected_indices[selected_indices['indexcode'] == index_code]\n",
    "        for _, row in filtered_indices.iterrows():\n",
    "            index_name = row['indexname']\n",
    "            daily_file_name = f\"{index_name.replace('.', '_')}.csv\"\n",
    "            daily_file_path = os.path.join(daily_data_path, daily_file_name)\n",
    "            try:\n",
    "                daily_data = pd.read_csv(daily_file_path)\n",
    "                df, finaldf, selectedscript = getpredictedvalues(daily_data)\n",
    "                predicted_values = finaldf['Close'].tail(5).values.tolist()\n",
    "                output_data = {\n",
    "                    'Run Date': current_date,\n",
    "                    'Index Name': index_name,\n",
    "                    'Model': df['Model'].iloc[0],\n",
    "                    'Train R2 Score': df['Train R2 Score'].iloc[0],\n",
    "                    'Test R2 Score': df['Test R2 Score'].iloc[0],\n",
    "                    'Day 1': predicted_values[0],\n",
    "                    'Day 2': predicted_values[1],\n",
    "                    'Day 3': predicted_values[2],\n",
    "                    'Day 4': predicted_values[3],\n",
    "                    'Day 5': predicted_values[4]\n",
    "                }\n",
    "                all_output_data.append(output_data)\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing {index_name}: {str(e)}\")\n",
    "\n",
    "    # Define columns to maintain order\n",
    "    columns = ['Run Date', 'Index Name', 'Model', 'Train R2 Score', 'Test R2 Score',\n",
    "               'Day 1', 'Day 2', 'Day 3', 'Day 4', 'Day 5']\n",
    "    output_df = pd.DataFrame(all_output_data, columns=columns)\n",
    "\n",
    "    # Update existing CSV or create new\n",
    "    if os.path.exists(output_csv_file):\n",
    "        existing_df = pd.read_csv(output_csv_file)\n",
    "        existing_df = existing_df[columns]\n",
    "        combined_df = pd.concat([existing_df, output_df], ignore_index=True)\n",
    "        combined_df = combined_df.drop_duplicates(subset=['Run Date', 'Index Name'], keep='last')\n",
    "    else:\n",
    "        combined_df = output_df\n",
    "\n",
    "    combined_df.to_csv(output_csv_file, index=False)\n",
    "    print(f\"\\nPredictions saved to {output_csv_file}\")\n",
    "\n",
    "    # Print the output DataFrame in a tabular format\n",
    "    print(\"\\nFinal Output:\")\n",
    "    print(tabulate(combined_df, headers='keys', tablefmt='fancy_grid', showindex=False))\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {str(e)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
