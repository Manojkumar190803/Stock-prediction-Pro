{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LSTM CODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import yfinance as yf\n",
    "import os\n",
    "from tabulate import tabulate\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM\n",
    "import warnings\n",
    "import datetime as dt\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create dataset for time-series prediction\n",
    "def create_dataset(dataset, time_step=1):\n",
    "    dataX, dataY = [], []\n",
    "    for i in range(len(dataset) - time_step - 1):\n",
    "        a = dataset[i:(i + time_step), 0]\n",
    "        dataX.append(a)\n",
    "        dataY.append(dataset[i + time_step, 0])\n",
    "    return np.array(dataX), np.array(dataY)\n",
    "\n",
    "# Main function to get predicted values\n",
    "def getpredictedvalues(selectedscript_1, start_date='2021-01-01', end_date='2025-01-01'):\n",
    "    selectedscript_2 = selectedscript_1.dropna().reset_index(drop=True)\n",
    "    selectedscript = selectedscript_2.copy()\n",
    "    selectedscript['Date'] = pd.to_datetime(selectedscript['Date'], format='%Y-%m-%d')\n",
    "    if start_date and end_date:\n",
    "        selectedscript = selectedscript[(selectedscript['Date'] >= start_date) & (selectedscript['Date'] <= end_date)]\n",
    "    selectedscript = selectedscript.set_index('Date')\n",
    "    close_df = selectedscript[['Close']].reset_index()\n",
    "    close_stock = close_df.copy()\n",
    "    del close_df['Date']\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    closedf = scaler.fit_transform(np.array(close_df).reshape(-1, 1))\n",
    "    training_size = int(len(closedf) * 0.80)\n",
    "    test_size = len(closedf) - training_size\n",
    "    train_data, test_data = closedf[0:training_size, :], closedf[training_size:len(closedf), :1]\n",
    "    time_step = 13\n",
    "    X_train, y_train = create_dataset(train_data, time_step)\n",
    "    X_test, y_test = create_dataset(test_data, time_step)\n",
    "    X_train = X_train.reshape(X_train.shape[0], X_train.shape[1], 1)\n",
    "    X_test = X_test.reshape(X_test.shape[0], X_test.shape[1], 1)\n",
    "    model = Sequential([\n",
    "        LSTM(32, return_sequences=True, input_shape=(time_step, 1)),\n",
    "        LSTM(32, return_sequences=True),\n",
    "        LSTM(32),\n",
    "        Dense(1)\n",
    "    ])\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10, batch_size=32, verbose=1)\n",
    "    train_predict = model.predict(X_train)\n",
    "    test_predict = model.predict(X_test)\n",
    "    train_predict = scaler.inverse_transform(train_predict)\n",
    "    test_predict = scaler.inverse_transform(test_predict)\n",
    "    original_ytrain = scaler.inverse_transform(y_train.reshape(-1, 1))\n",
    "    original_ytest = scaler.inverse_transform(y_test.reshape(-1, 1))\n",
    "    train_r2_lstm = r2_score(original_ytrain, train_predict)\n",
    "    test_r2_lstm = r2_score(original_ytest, test_predict)\n",
    "    look_back = time_step\n",
    "    x_input = test_data[len(test_data) - time_step:].reshape(1, -1)\n",
    "    temp_input = list(x_input)[0].tolist()\n",
    "    lst_output = []\n",
    "    n_steps = time_step\n",
    "    pred_days = 5\n",
    "    i = 0\n",
    "    while i < pred_days:\n",
    "        if len(temp_input) > time_step:\n",
    "            x_input = np.array(temp_input[1:]).reshape(1, -1)\n",
    "            x_input = x_input.reshape((1, n_steps, 1))\n",
    "            yhat = model.predict(x_input, verbose=0)\n",
    "            temp_input.extend(yhat[0].tolist())\n",
    "            temp_input = temp_input[1:]\n",
    "            lst_output.extend(yhat.tolist())\n",
    "            i += 1\n",
    "        else:\n",
    "            x_input = x_input.reshape((1, n_steps, 1))\n",
    "            yhat = model.predict(x_input, verbose=0)\n",
    "            temp_input.extend(yhat[0].tolist())\n",
    "            lst_output.extend(yhat.tolist())\n",
    "            i += 1\n",
    "    lstmdf = scaler.inverse_transform(np.array(closedf.tolist() + lst_output).reshape(-1, 1)).flatten().tolist()\n",
    "    finaldf = pd.DataFrame({'Close': lstmdf})\n",
    "    data = {\"Model\": [\"LSTM\"], \"Train R2 Score\": [train_r2_lstm], \"Test R2 Score\": [test_r2_lstm]}\n",
    "    df = pd.DataFrame(data)\n",
    "    return df, finaldf, selectedscript"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths and configurations\n",
    "file_path = 'C://Users//manoj//Downloads//Major project data//Major pro source codes//DATASETS//filtered_indices_output.csv'\n",
    "daily_data_path = 'C://Users//manoj//Downloads//Major project data//Major pro source codes//DATASETS//Daily_data'\n",
    "output_csv_file = 'C://Users//manoj//Downloads//Major project data//Major pro source codes//DATASETS//lstm_prediction_output.csv'\n",
    "sectors_file_path = 'C://Users//manoj//Downloads//Major project data//Major pro source codes//DATASETS//indicesstocks.csv'\n",
    "try:\n",
    "    # Check if the file exists\n",
    "    if os.path.exists(file_path):\n",
    "        print(f\"File found: {file_path}\")\n",
    "        selected_indices = pd.read_csv(file_path, on_bad_lines='skip')  # Updated line\n",
    "    else:\n",
    "        print(f\"File not found: {file_path}\")\n",
    "        raise FileNotFoundError(f\"The specified file does not exist: {file_path}\")\n",
    "\n",
    "    all_output_data = []\n",
    "    unique_index_codes = selected_indices['indexcode'].unique()\n",
    "    current_date = dt.datetime.now().strftime(\"%Y-%m-%d\")\n",
    "\n",
    "    for index_code in unique_index_codes:\n",
    "        filtered_indices = selected_indices[selected_indices['indexcode'] == index_code]\n",
    "        for _, row in filtered_indices.iterrows():\n",
    "            index_name = row['indexname']\n",
    "            daily_file_name = f\"{index_name.replace('.', '_')}.csv\"\n",
    "            daily_file_path = os.path.join(daily_data_path, daily_file_name)\n",
    "            try:\n",
    "                daily_data = pd.read_csv(daily_file_path)\n",
    "                df, finaldf, selectedscript = getpredictedvalues(daily_data)\n",
    "                predicted_values = finaldf['Close'].tail(5).values.tolist()\n",
    "                output_data = {\n",
    "                    'Run Date': current_date,\n",
    "                    'Index Name': index_name,\n",
    "                    'Model': df['Model'].iloc[0],\n",
    "                    'Train R2 Score': df['Train R2 Score'].iloc[0],\n",
    "                    'Test R2 Score': df['Test R2 Score'].iloc[0],\n",
    "                    'Day 1': predicted_values[0],\n",
    "                    'Day 2': predicted_values[1],\n",
    "                    'Day 3': predicted_values[2],\n",
    "                    'Day 4': predicted_values[3],\n",
    "                    'Day 5': predicted_values[4]\n",
    "                }\n",
    "                # Check for duplicates BEFORE appending\n",
    "                duplicate = False\n",
    "                for existing_data in all_output_data:\n",
    "                    if existing_data['Run Date'] == output_data['Run Date'] and existing_data['Index Name'] == output_data['Index Name']:\n",
    "                        duplicate = True\n",
    "                        break\n",
    "                if not duplicate:\n",
    "                    all_output_data.append(output_data)\n",
    "                else:\n",
    "                    print(f\"Duplicate entry found for {index_name} on {current_date}. Skipping.\")\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing {index_name}: {str(e)}\")\n",
    "\n",
    "    # Define columns to maintain order\n",
    "    columns = ['Run Date', 'Index Name', 'Model', 'Train R2 Score', 'Test R2 Score',\n",
    "               'Day 1', 'Day 2', 'Day 3', 'Day 4', 'Day 5']\n",
    "    output_df = pd.DataFrame(all_output_data, columns=columns)\n",
    "\n",
    "    # Update existing CSV or create new\n",
    "    # combined_df.to_csv(output_csv_file, index=False) #old code\n",
    "    output_df.to_csv(output_csv_file, index=False) #new code\n",
    "\n",
    "    print(f\"//nPredictions saved to {output_csv_file}\")\n",
    "\n",
    "    # Print the output DataFrame in a tabular format\n",
    "    print(\"//nFinal Output:\")\n",
    "    print(tabulate(output_df, headers='keys', tablefmt='fancy_grid', showindex=False))\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {str(e)}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
