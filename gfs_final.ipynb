{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*****GENERATING INDICES DATA*****"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datetime as dt\n",
    "from pathlib import Path\n",
    "import pandas_ta as ta\n",
    "from tabulate import tabulate\n",
    "\n",
    "def append_row(df, row):\n",
    "    \"\"\"Appends a new row to a pandas DataFrame.\"\"\"\n",
    "    return pd.concat([df, pd.DataFrame([row], columns=row.index)]).reset_index(drop=True)\n",
    "\n",
    "def getRSI14(csvfilename):\n",
    "    \"\"\"Calculates the RSI (14 period) for a given CSV file.\"\"\"\n",
    "    if Path(csvfilename).is_file():\n",
    "        try:\n",
    "            df = pd.read_csv(csvfilename)\n",
    "            if df.empty:\n",
    "                return 0.00, 0.00\n",
    "            else:\n",
    "                df['Close'] = pd.to_numeric(df['Close'], errors='coerce')\n",
    "                df['rsi14'] = ta.rsi(df['Close'], length=14)\n",
    "                if pd.isna(df['rsi14'].iloc[-1]):\n",
    "                    return 0.00, 0.00\n",
    "                else:\n",
    "                    rsival = df['rsi14'].iloc[-1].round(2)\n",
    "                    ltp = df['Close'].iloc[-1].round(2)\n",
    "                return rsival, ltp\n",
    "        except Exception as e:\n",
    "            print(f\"Error reading {csvfilename}: {e}\")\n",
    "            return 0.00, 0.00\n",
    "    else:\n",
    "        print(f\"File does not exist: {csvfilename}\")\n",
    "        return 0.00, 0.00\n",
    "\n",
    "def dayweekmonth_datasets(symbol, symbolname):\n",
    "    \"\"\"Calculates RSI for daily, weekly, and monthly data.\"\"\"\n",
    "    if symbol.endswith('.NS'):\n",
    "        symbol = symbol.replace(\".NS\", \"_NS\")\n",
    "\n",
    "    base_path = Path(\"C:/Users/manoj/Downloads/Major project data/Major pro source codes/DATASETS\")\n",
    "    daylocationstr = base_path / \"Daily_data\" / f\"{symbol}.csv\"\n",
    "    weeklocationstr = base_path / \"Weekly_data\" / f\"{symbol}.csv\"\n",
    "    monthlocationstr = base_path / \"Monthly_data\" / f\"{symbol}.csv\"\n",
    "\n",
    "    cday = dt.datetime.today().strftime('%d/%m/%Y')\n",
    "    dayrsi14, dltp = getRSI14(daylocationstr)\n",
    "    weekrsi14, wltp = getRSI14(weeklocationstr)\n",
    "    monthrsi14, mltp = getRSI14(monthlocationstr)\n",
    "\n",
    "    new_row = pd.Series({\n",
    "        'entrydate': cday,\n",
    "        'indexcode': symbol,\n",
    "        'indexname': symbolname.strip(),\n",
    "        'dayrsi14': dayrsi14,\n",
    "        'weekrsi14': weekrsi14,\n",
    "        'monthrsi14': monthrsi14\n",
    "    })\n",
    "    return new_row\n",
    "\n",
    "def generateGFS(scripttype):\n",
    "    \"\"\"Generates the GFS report based on the provided scripttype.\"\"\"\n",
    "    indicesdf = pd.DataFrame(columns=['entrydate', 'indexcode', 'indexname', 'dayrsi14', 'weekrsi14', 'monthrsi14'])\n",
    "\n",
    "    base_path = Path(\"C:/Users/manoj/Downloads/Major project data/Major pro source codes/DATASETS\")\n",
    "    fname = base_path / scripttype\n",
    "    csvfilename = base_path / f\"GFS_{scripttype}.csv\"\n",
    "\n",
    "    try:\n",
    "        with open(fname) as f:\n",
    "            for line in f:\n",
    "                if \",\" not in line:\n",
    "                    continue\n",
    "                symbol, symbolname = line.split(\",\")[0], line.split(\",\")[1]\n",
    "                symbol = symbol.strip()\n",
    "                new_row = dayweekmonth_datasets(symbol, symbolname)\n",
    "                indicesdf = append_row(indicesdf, new_row)\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {fname}: {e}\")\n",
    "\n",
    "    indicesdf.to_csv(csvfilename, index=False)\n",
    "    return indicesdf\n",
    "\n",
    "# Generate the GFS report\n",
    "df3 = generateGFS(\"indicesdf.csv\")\n",
    "\n",
    "# Display the DataFrame in tabular format using tabulate\n",
    "print(tabulate(df3, headers='keys', tablefmt='fancy_grid'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*****GFS LOGIC FOR INDICES*****"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datetime as dt\n",
    "from pathlib import Path\n",
    "import pandas_ta as ta\n",
    "from tabulate import tabulate\n",
    "import os\n",
    "\n",
    "def append_row(df, row):\n",
    "    \"\"\"Appends a new row to a pandas DataFrame.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): The existing DataFrame.\n",
    "        row (pd.Series): The new row to append.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: The DataFrame with the new row appended.\n",
    "    \"\"\"\n",
    "    return pd.concat([\n",
    "        df,\n",
    "        pd.DataFrame([row], columns=row.index)\n",
    "    ]).reset_index(drop=True)\n",
    "\n",
    "def getRSI14_and_BB(csvfilename):\n",
    "    \"\"\"Calculates RSI (14 period) and Bollinger Bands (20 period, 2 std.dev) for a given CSV file.\n",
    "\n",
    "    Args:\n",
    "        csvfilename (str): Path to the CSV file.\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing RSI value, last close price, lower band, and middle band.\n",
    "        (float, float, float, float)\n",
    "    \"\"\"\n",
    "    if Path(csvfilename).is_file():\n",
    "        try:\n",
    "            df = pd.read_csv(csvfilename)\n",
    "            if df.empty or 'Close' not in df.columns:\n",
    "                return 0.00, 0.00, 0.00, 0.00\n",
    "            else:\n",
    "                df['Close'] = pd.to_numeric(df['Close'], errors='coerce')\n",
    "                df['rsi14'] = ta.rsi(df['Close'], length=14)\n",
    "                bb = ta.bbands(df['Close'], length=20)\n",
    "                if bb is None or df['rsi14'] is None:\n",
    "                    return 0.00, 0.00, 0.00, 0.00\n",
    "                df['lowerband'] = bb['BBL_20_2.0']\n",
    "                df['middleband'] = bb['BBM_20_2.0']\n",
    "                if pd.isna(df['rsi14'].iloc[-1]) or pd.isna(df['lowerband'].iloc[-1]) or pd.isna(df['middleband'].iloc[-1]):\n",
    "                    return 0.00, 0.00, 0.00, 0.00\n",
    "                else:\n",
    "                    rsival = df['rsi14'].iloc[-1].round(2)\n",
    "                    ltp = df['Close'].iloc[-1].round(2)\n",
    "                    lowerband = df['lowerband'].iloc[-1].round(2)\n",
    "                    middleband = df['middleband'].iloc[-1].round(2)\n",
    "                    return rsival, ltp, lowerband, middleband\n",
    "        except Exception as e:\n",
    "            print(f\"Error reading {csvfilename}: {e}\")\n",
    "            return 0.00, 0.00, 0.00, 0.00\n",
    "    else:\n",
    "        print(f\"File does not exist: {csvfilename}\")\n",
    "        return 0.00, 0.00, 0.00, 0.00\n",
    "\n",
    "def dayweekmonth_datasets(symbol, symbolname):\n",
    "    \"\"\"Calculates RSI, Bollinger Bands, and other metrics for daily, weekly, and monthly data.\n",
    "\n",
    "    Args:\n",
    "        symbol (str): The symbol of the asset.\n",
    "        symbolname (str): The name of the asset.\n",
    "\n",
    "    Returns:\n",
    "        pd.Series: A Series containing the calculated metrics.\n",
    "    \"\"\"\n",
    "    daylocationstr = f'DATASETS/Daily_data/{symbol}.csv'\n",
    "    weeklocationstr = f'DATASETS/Weekly_data/{symbol}.csv'\n",
    "    monthlocationstr = f'DATASETS/Monthly_data/{symbol}.csv'\n",
    "\n",
    "    cday = dt.datetime.today().strftime('%d/%m/%Y')\n",
    "    dayrsi14, dltp, daylowerband, daymiddleband = getRSI14_and_BB(daylocationstr)\n",
    "    weekrsi14, wltp, weeklowerband, weekmiddleband = getRSI14_and_BB(weeklocationstr)\n",
    "    monthrsi14, mltp, monthlowerband, monthmiddleband = getRSI14_and_BB(monthlocationstr)\n",
    "\n",
    "    new_row = pd.Series({\n",
    "        'entrydate': cday,\n",
    "        'indexcode': symbol,\n",
    "        'indexname': symbolname,\n",
    "        'dayrsi14': dayrsi14,\n",
    "        'weekrsi14': weekrsi14,\n",
    "        'monthrsi14': monthrsi14,\n",
    "        'dltp': dltp,\n",
    "        'daylowerband': daylowerband,\n",
    "        'daymiddleband': daymiddleband,\n",
    "        'weeklowerband': weeklowerband,\n",
    "        'weekmiddleband': weekmiddleband,\n",
    "        'monthlowerband': monthlowerband,\n",
    "        'monthmiddleband': monthmiddleband\n",
    "    })\n",
    "    return new_row\n",
    "\n",
    "def generateGFS(scripttype):\n",
    "    \"\"\"Generates the GFS report based on the provided scripttype.\n",
    "\n",
    "    Args:\n",
    "        scripttype (str): The name of the scripttype file.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: The DataFrame containing the GFS report.\n",
    "    \"\"\"\n",
    "    indicesdf = pd.DataFrame(columns=['entrydate', 'indexcode', 'indexname', 'dayrsi14', 'weekrsi14', 'monthrsi14', 'dltp', 'daylowerband', 'daymiddleband', 'weeklowerband', 'weekmiddleband', 'monthlowerband', 'monthmiddleband'])\n",
    "\n",
    "    fname = f'DATASETS/{scripttype}.csv'\n",
    "    csvfilename = f'GFS_{scripttype}.csv'\n",
    "    try:\n",
    "        with open(fname) as f:\n",
    "            for line in f:\n",
    "                if \",\" not in line:\n",
    "                    continue\n",
    "                symbol, symbolname = line.split(\",\")[0], line.split(\",\")[1]\n",
    "                symbol = symbol.replace(\"\\n\", \"\")\n",
    "                new_row = dayweekmonth_datasets(symbol, symbolname)\n",
    "                indicesdf = append_row(indicesdf, new_row)\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {fname}: {e}\")\n",
    "\n",
    "    indicesdf.to_csv(csvfilename, index=False)\n",
    "    return indicesdf\n",
    "\n",
    "# Assuming 'DATASETS/indicesdf.csv' exists and is in the correct format\n",
    "df3 = generateGFS('indicesdf')\n",
    "\n",
    "df4 = df3.loc[\n",
    "    (df3['monthrsi14'] >= 60.00) &\n",
    "    (df3['weekrsi14'] >= 60.00) &\n",
    "    df3['dayrsi14'].between(30, 70) &\n",
    "    (df3['dltp'] > df3['daylowerband']) &\n",
    "    (df3['dltp'] < df3['daymiddleband'])\n",
    "]\n",
    "\n",
    "df4 = df4.sort_values(by=['dayrsi14'], ascending=True)\n",
    "\n",
    "if df4.empty:\n",
    "    print(\"\\033[1mNO INDICES QUALIFIES THE GFS CRITERIA\\033[0m\")\n",
    "else:\n",
    "    print(tabulate(df4, headers='keys', tablefmt='fancy_grid', showindex=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*****STOCKS DATA IN INDICES*****"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tabulate import tabulate\n",
    "\n",
    "def traverse_files(file1_path, file2_path):\n",
    "    # Read the first file\n",
    "    with open(file1_path, 'r') as f1:\n",
    "        file1_data = f1.readlines()\n",
    "\n",
    "    # Read the second file\n",
    "    with open(file2_path, 'r') as f2:\n",
    "        file2_data = f2.readlines()\n",
    "\n",
    "    # Use a dictionary to store the second file's data by its first column values\n",
    "    file2_dict = {}\n",
    "    for line in file2_data:\n",
    "        # Strip whitespace and split by commas\n",
    "        parts = line.strip().split(',')\n",
    "        if parts:  # Ensure line is not empty\n",
    "            # Store the rest of the data by the first column\n",
    "            file2_dict[parts[0]] = parts[1:]\n",
    "\n",
    "    # Store matched results\n",
    "    matched_results = []\n",
    "\n",
    "    # Traverse through the first file and check for matches in the second file\n",
    "    for line in file1_data:\n",
    "        # Strip whitespace and split by commas\n",
    "        parts = line.strip().split(',')\n",
    "        if parts and parts[0] in file2_dict:\n",
    "            # Prepare the matched result\n",
    "            matched_results.append([parts[0]] + file2_dict[parts[0]])\n",
    "\n",
    "    # Print the matched results in a tabular format\n",
    "    if matched_results:\n",
    "        headers = ['Index Code'] + [f'Column {i+1}' for i in range(len(matched_results[0]) - 1)]\n",
    "        print(tabulate(matched_results, headers=headers,tablefmt='fancy_grid')) #tablefmt='psql'))\n",
    "    else:\n",
    "        print(\"No matches found!\")\n",
    "\n",
    "# Specify the paths to your files\n",
    "file1_path = r\"C:\\\\Users\\manoj\\Downloads\\Major project data\\Major pro source codes\\DATASETS\\indicesdf.csv\"  # Replace with your actual file path\n",
    "file2_path = r\"C:\\\\Users\\manoj\\Downloads\\Major project data\\Major pro source codes\\DATASETS\\indicesstocks.csv\"  # Replace with your actual file path\n",
    "\n",
    "# Call the function\n",
    "traverse_files(file1_path, file2_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*****GFS LOGIC FOR STOCKS*****"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datetime as dt\n",
    "from pathlib import Path\n",
    "import pandas_ta as ta\n",
    "from tabulate import tabulate\n",
    "\n",
    "def append_row(df, row):\n",
    "    \"\"\"Appends a new row to a pandas DataFrame if the row is not empty.\"\"\"\n",
    "    if row.isnull().all():\n",
    "        return df  # Do not append if the row is all NA\n",
    "    return pd.concat([df, pd.DataFrame([row], columns=row.index)]).reset_index(drop=True)\n",
    "\n",
    "def getRSI14_and_BB(csvfilename):\n",
    "    \"\"\"Calculates RSI (14 period) and Bollinger Bands (20 period, 2 std.dev) for a given CSV file.\"\"\"\n",
    "    if Path(csvfilename).is_file():\n",
    "        try:\n",
    "            df = pd.read_csv(csvfilename)\n",
    "            if df.empty or 'Close' not in df.columns:\n",
    "                return 0.00, 0.00, 0.00, 0.00\n",
    "            else:\n",
    "                df['Close'] = pd.to_numeric(df['Close'], errors='coerce')\n",
    "                df['rsi14'] = ta.rsi(df['Close'], length=14)\n",
    "                bb = ta.bbands(df['Close'], length=20)\n",
    "                if bb is None or df['rsi14'] is None:\n",
    "                    return 0.00, 0.00, 0.00, 0.00\n",
    "                df['lowerband'] = bb['BBL_20_2.0']\n",
    "                df['middleband'] = bb['BBM_20_2.0']\n",
    "                if pd.isna(df['rsi14'].iloc[-1]) or pd.isna(df['lowerband'].iloc[-1]) or pd.isna(df['middleband'].iloc[-1]):\n",
    "                    return 0.00, 0.00, 0.00, 0.00\n",
    "                else:\n",
    "                    rsival = df['rsi14'].iloc[-1].round(2)\n",
    "                    ltp = df['Close'].iloc[-1].round(2)\n",
    "                    lowerband = df['lowerband'].iloc[-1].round(2)\n",
    "                    middleband = df['middleband'].iloc[-1].round(2)\n",
    "                    return rsival, ltp, lowerband, middleband\n",
    "        except Exception as e:\n",
    "            print(f\"Error reading {csvfilename}: {e}\")\n",
    "            return 0.00, 0.00, 0.00, 0.00\n",
    "    else:\n",
    "        print(f\"File does not exist: {csvfilename}\")\n",
    "        return 0.00, 0.00, 0.00, 0.00\n",
    "\n",
    "def dayweekmonth_datasets(symbol, symbolname):\n",
    "    \"\"\"Calculates RSI, Bollinger Bands, and other metrics for daily, weekly, and monthly data.\"\"\"\n",
    "    # Replace periods with underscores in the symbol for file naming\n",
    "    symbol_with_underscore = symbol.replace('.', '_')\n",
    "\n",
    "    # Construct the file paths using the modified symbol\n",
    "    daylocationstr = f'DATASETS/Daily_data/{symbol_with_underscore}.csv'\n",
    "    weeklocationstr = f'DATASETS/Weekly_data/{symbol_with_underscore}.csv'\n",
    "    monthlocationstr = f'DATASETS/Monthly_data/{symbol_with_underscore}.csv'\n",
    "\n",
    "    cday = dt.datetime.today().strftime('%d/%m/%Y')\n",
    "    dayrsi14, dltp, daylowerband, daymiddleband = getRSI14_and_BB(daylocationstr)\n",
    "    weekrsi14, wltp, weeklowerband, weekmiddleband = getRSI14_and_BB(weeklocationstr)\n",
    "    monthrsi14, mltp, monthlowerband, monthmiddleband = getRSI14_and_BB(monthlocationstr)\n",
    "\n",
    "    new_row = pd.Series({\n",
    "        'entrydate': cday,\n",
    "        'indexcode': symbol,\n",
    "        'indexname': symbolname,\n",
    "        'dayrsi14': dayrsi14,\n",
    "        'weekrsi14': weekrsi14,\n",
    "        'monthrsi14': monthrsi14,\n",
    "        'dltp': dltp,\n",
    "        'daylowerband': daylowerband,\n",
    "        'daymiddleband': daymiddleband,\n",
    "        'weeklowerband': weeklowerband,\n",
    "        'weekmiddleband': weekmiddleband,\n",
    "        'monthlowerband': monthlowerband,\n",
    "        'monthmiddleband': monthmiddleband\n",
    "    })\n",
    "    return new_row\n",
    "\n",
    "def generateGFS(scripttype):\n",
    "    \"\"\"Generates the GFS report based on the provided scripttype.\"\"\"\n",
    "    indicesdf = pd.DataFrame(columns=['entrydate', 'indexcode', 'indexname', 'dayrsi14', 'weekrsi14', 'monthrsi14', 'dltp', 'daylowerband', 'daymiddleband', 'weeklowerband', 'weekmiddleband', 'monthlowerband', 'monthmiddleband'])\n",
    "\n",
    "    fname = f'DATASETS/{scripttype}.csv'\n",
    "    csvfilename = f'GFS_{scripttype}.csv'\n",
    "    try:\n",
    "        with open(fname) as f:\n",
    "            for line in f:\n",
    "                if \",\" not in line:\n",
    "                    continue\n",
    "                symbol, symbolname = line.split(\",\")[0], line.split(\",\")[1]\n",
    "                symbol = symbol.replace(\"\\n\", \"\")\n",
    "                new_row = dayweekmonth_datasets(symbol, symbolname)\n",
    "                indicesdf = append_row(indicesdf, new_row)\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {fname}: {e}\")\n",
    "\n",
    "    indicesdf.to_csv(csvfilename, index=False)\n",
    "    return indicesdf\n",
    "\n",
    "def read_indicesstocks(csvfilename):\n",
    "    \"\"\"Reads the indicesstocks CSV file and returns a dictionary of indices and their stocks.\"\"\"\n",
    "    if Path(csvfilename).is_file():\n",
    "        try:\n",
    "            df = pd.read_csv(csvfilename, header=None, on_bad_lines='skip')  # Use 'on_bad_lines' for newer versions\n",
    "            indices_dict = {}\n",
    "            for index, row in df.iterrows():\n",
    "                index_code = row[0].strip()  # Get the index code\n",
    "                stocks = row[1:].dropna().tolist()  # Get the stocks, drop NaN values\n",
    "                indices_dict[index_code] = stocks\n",
    "            return indices_dict\n",
    "        except Exception as e:\n",
    "            print(f\"Error reading {csvfilename}: {e}\")\n",
    "            return {}\n",
    "    else:\n",
    "        print(f\"File does not exist: {csvfilename}\")\n",
    "        return {}\n",
    "\n",
    "# Main execution\n",
    "# Main execution\n",
    "indicesdf_path = 'DATASETS/indicesdf.csv'\n",
    "indicesstocks_path = r'C:\\Users\\manoj\\Downloads\\Major project data\\Major pro source codes\\DATASETS\\indicesstocks.csv'\n",
    "filtered_indices_path = 'DATASETS/filtered_indices.csv'  # Path for the new CSV file\n",
    "\n",
    "# Generate GFS report\n",
    "df3 = generateGFS('indicesdf')\n",
    "\n",
    "# Filter based on criteria\n",
    "df4 = df3.loc[\n",
    "    (df3['monthrsi14'] >= 60.00) &\n",
    "    (df3['weekrsi14'] >= 60.00) &\n",
    "    df3['dayrsi14'].between(30, 70) &\n",
    "    (df3['dltp'] > df3['daylowerband']) &\n",
    "    (df3['dltp'] < df3['daymiddleband'])\n",
    "]\n",
    "\n",
    "# Extract only the indexcode for the filtered indices\n",
    "filtered_indexcodes = df4[['indexcode']]\n",
    "\n",
    "# Save the filtered indexcodes to a new CSV file, overwriting any existing file\n",
    "filtered_indexcodes.to_csv(filtered_indices_path, index=False)\n",
    "\n",
    "# Check if any indices qualified\n",
    "if filtered_indexcodes.empty:\n",
    "    print(\"\\033[1mNO STOCKS QUALIFY THE GFS CRITERIA\\033[0m\")\n",
    "else:\n",
    "    # Read indices from indicesstocks\n",
    "    indicesstocks = read_indicesstocks(indicesstocks_path)\n",
    "\n",
    "    # Read filtered indices\n",
    "    filtered_indices = filtered_indexcodes['indexcode'].tolist()\n",
    "\n",
    "    # Flag to track if any stocks qualify\n",
    "    any_stocks_qualified = False\n",
    "\n",
    "    # Compare and run GFS for matched indices\n",
    "    for index in filtered_indices:\n",
    "        if index in indicesstocks:\n",
    "            print(f\"Running GFS for matched index: {index}\")\n",
    "            stocks = indicesstocks[index]  # Get the list of stocks for the matched index \n",
    "\n",
    "            # Traverse through the stocks starting from the next position\n",
    "            for stock in stocks[1:]:  # Start from the second stock (index + 1)\n",
    "                if stock:  # Check if stock is not empty\n",
    "                    print(f\"Running GFS for stock: {stock}\")\n",
    "                    try:\n",
    "                        # Call the GFS function for each stock\n",
    "                        matched_row = dayweekmonth_datasets(stock, stock)  # Using stock as both symbol and symbolname\n",
    "                        \n",
    "                        # Use tabulate to print the row with a specific format\n",
    "                        print(tabulate([matched_row], headers='keys', tablefmt='fancy_grid', showindex=False))\n",
    "                        \n",
    "                        # Set the flag to True since we have a qualifying stock\n",
    "                        any_stocks_qualified = True\n",
    "                    except Exception as e:\n",
    "                        print(f\"Error processing stock {stock}: {e}\")\n",
    "                else:\n",
    "                    print(f\"Skipping empty stock name in index {index}.\")\n",
    "\n",
    "    # Print the message only if no stocks qualified\n",
    "    if not any_stocks_qualified:\n",
    "        print(\"\\033[1mNO STOCKS QUALIFY THE GFS CRITERIA\\033[0m\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
